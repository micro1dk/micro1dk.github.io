---
title: 차원축소
layout: default
parent: 머신러닝
nav_order: 12
---

# 차원 축소

수십~수백개의 Feature들을 줄이자. 원본 데이터의 정보를 최대한으로 유지한 채로 차원 축소를 할것인가? 

차원 축소는 크게 두 가지 유형으로 나뉜다.

* Feature Selection - 모델을 잘 설명할 수 있는 피쳐들을 선택
* Feature Extraction - 피처들을 함축적으로 더 잘 설명할 수 있는 다른 공간으로 매핑해 추출하는 것
  * ex) 연령, 소득, 구매이력과 같은 피쳐에서 '경제적 수준', '구매 활동'과 같은 새로운 피쳐를 추출해냄.

차원축소는 단순히 데이터의 압축을 의미하는 것이아닌 데이터를 더 잘 설명할 수 있는 잠재적(Latent)요소를 추출하는 데 있다.

흔히 사용되는 차원 축소 기법에는 

* 주성분 분석(PCA)
* 선형 판별 분석(LDA)
* t-SNE(t-Distributed Stochastic Neighbor Embedding)





## PCA(Principal Component Analysis)

PCA는 주성분 분석이라고 한다. 고차원의 원본 데이터를 저차원의 **부분 공간으로 투영**하여 데이터를 축소하는 기법이다.

![](../../assets/images/ml/pca0.png)

분산이 최대인 첫 번째 축을 나타내었다. 데이터가 가장 넓게 퍼져있는 방향을 찾은 것이다.

PCA에서 분산을 기반으로 축을 생성하는 이유는 **데이터의 주요한 패턴**이 **가장 큰 분산을 가진 방향**에 위치하기 때문이다. PCA 축을 정사영했을 때 **겹치는 데이터가 최소**가된다.

 다음은 PCA과정이다. 

1. **PCA1 생성** - PCA는 먼저 원본 데이터에 가장 큰 데이터 변동성(Variance)을 기반으로 첫 번째 벡터 축을 생성한다. PCA1축으로 정사영할 때 겹치는 데이터가 최소가 되게하기 위함.
2. **PCA1 정사영** - 예시로 겹치는 데이터가 100개라고 가정한다.
3. **PCA2 생성** - 이 PCA1축에 겹쳐지는 100개의 포인트를 설명할 수 있는 축 PCA2를 생성해야한다. 

 

따라서 PCA는 **데이터의 분산을 최대화하는 새로운 특성(주성분)**을 찾는 방법이라 볼 수있다. 이는 원래의 특성들이 가진 정보를 가능한 **적은 수의 새로운 특성으로 압축**하려는 시도이다.

이렇게 하면, 원래의 데이터 차원보다 적은 수의 차원을 가지면서도 원래 데이터에서 가장 중요한 정보를 유지할 수 있다. 



PCA의 세부적인 과정을 이해하기 위해 공분산을 이해해야한다.



## 공분산 행렬

### 공분산

공분산이란 두 변수간의 관계를 수치로 표현하는 개념. 보통 공분산을 -1에서 1 사이의 값으로 정규화한 상관계수(Correlation Coefficient)를 사용하여 두 변수 사이의 선형적 관계를 측정한다.

[상관관계 정리 글]()

* Cov(X, Y) > 0 - 공분산이 양수인 경우, 하나의 변수가 증가하면 다른 하나의 변수도 증가하는 경향이 있다.

* Cov(X, Y) < 0 - 공분산이 음수인 경우, 하나의 변수가 증가하면 다른 하나의 변수는 감소하는 경향이 있다.

* Cov(X, Y) = 0 - 공분산이 0인경우, 두 변수간에는 선형적인 관계가 없다.



### 고유벡터

**Eigenvector**는 공분산 행렬이 선형 변환될 때 방향은 변하지 않고 크기만 변하는 벡터를 의미한다. 공분산 행렬의 고유벡터는 데이터가 어떤 방향으로 분산되어 있는지 찾아준다.



### 고윳값

**Eigenvalue**는 고유벡터의 크기, 즉 원래 벡터가 얼마나 늘어나는지 나타내는 스칼라 값이다. 교윳값이 큰 순서대로 고유벡터를 정렬하면 **중요한 순서대로 주성분을 구성**하게 된다.



 

1. 데이터 행렬 X의 **공분산 행렬(Covariance Matrix)**을 계산한다.
   * 공분산은 두 변수가 어떻게 함께 변화하는지를 측정하는 통계량이다.
   * 데이터가 D 차원이고, N 개의 데이터를 가질 때, 공분산 행렬은 DxD 크기의 행렬이다.







## SVD(Singular Value Decomposition)

특이값분해