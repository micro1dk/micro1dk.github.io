# Feature Engineering

실제데이터는 깔끔하지 않을 수 있으며, 정규화와 같은 전처리 단계 외에도 기존의 Feature에서 정보를 추출하고 확장해야한다. Feature Engineering은 데이터 과학과 머신 러닝에서 매우 중요한 단계로, 원시 데이터를 더 유용하고 효과적인 형태로 변환하여 모델의 성능을 향상시키는 과정이다. 몇 가지 주요한 Feature Engineering 방법에 대해 설명한다.



- **수치화 (Numericalization)**: 범주형 데이터를 수치형 데이터로 변환한다 예를 들어, '남성'과 '여성'을 각각 0과 1로 변환할 수 있다.
- **범주형 변수 인코딩 (Categorical Variable Encoding)**: 원-핫 인코딩, 레이블 인코딩 등을 통해 범주형 변수를 모델이 이해할 수 있는 형태로 변환한다
- **일변량 변환 (Univariate Transformation)**: 로그 변환, 제곱근 변환 등을 사용하여 수치 데이터의 분포를 조정한다. 이는 데이터의 비대칭성을 줄이고 모델이 데이터를 더 잘 이해하도록 돕는다.
- **결측치 처리 (Handling Missing Values)**: 결측치를 평균(mean), 중앙값(median), 빈도수(mode)가 가장 높은 값 등으로 대체한다.
- **피처 스케일링 (Feature Scaling)**: 표준화(Standardization)나 정규화(Normalization)를 통해 서로 다른 스케일을 가진 피처들의 범위를 조정한다.
  - 표준화는 데이터의 평균을 0, 표준편차를 1로 조정하는 과정이다.
  - 정규화는 데이터의 범위를 특정 범위(예: 0과 1 사이)로 조정하는 과정이다.
- **피처 생성 (Feature Creation)**: 기존의 피처들을 조합하거나 변형하여 새로운 피처를 생성한다.
- **차원 축소 (Dimensionality Reduction)**: 주성분 분석(PCA), t-SNE, LDA 같은 기술을 사용하여 피처의 차원을 줄인다.
- **텍스트 데이터 처리 (Text Data Processing)**: 자연어 처리를 사용하여 텍스트 데이터를 수치화합니다. 예를 들어, 토큰화, 스태밍, 벡터화(TF-IDF, Word2Vec 등) 등의 방법이 있다
- **시계열 데이터 처리 (Time Series Data Processing)**





## 이상치 탐지&처리

이상치(Outlier)는 데이터의 일반적인 패턴에서 벗어난 값으로, 머신 러닝 모델의 성능에 부정적인 영향을 미칠 수 있다. Feature Engineering 과정에서 이상치를 감지하고 처리하는 것은 중요한 단계이다. 이상치를 감지하고 처리하는 주요 방법들에 대해 설명한다.



1. **통계적 방법**
   - **Z-점수**: 데이터 포인트의 Z-점수는 해당 값이 평균으로부터 얼마나 떨어져 있는지를 나타낸다. 일반적으로 Z-점수가 ±3 이상인 경우, 데이터 포인트를 이상치로 간주할 수 있다
   - **IQR (Interquartile Range)**: IQR은 데이터의 25번째 백분위수(Q1)와 75번째 백분위수(Q3)의 차이. 일반적으로, Q1-1.5*IQR 미만이거나 Q3+1.5*IQR 초과하는 값들을 이상치로 간주된다.
2. **시각적 방법**
   - **박스 플롯(Box Plot)**: IQR을 기반으로 이상치를 나타내며, 이상치는 박스 외부에 있는 점들이다.
   - **산점도(Scatter Plot)**: 두 변수 간의 관계를 보여주는 산점도를 통해 이상치를 시각적으로 식별할 수 있다.
3. **다변량 방법**:
   - **Mahalanobis Distance**: 이 방법은 데이터 포인트가 다변량 데이터 세트의 중심에서 얼마나 멀리 떨어져 있는지를 측정한다. 먼 거리는 이상치일 가능성이 높음을 나타낸다
   - **클러스터링 기반 방법**: K-평균 같은 클러스터링 알고리즘을 사용하여 이상치를 식별할 수 있습니다. 이상치는 일반적으로 클러스터의 중심에서 멀리 떨어져 있습니다.
4. **기계학습 기반 방법**:
   - **Isolation Forest**: 이상치 탐지를 위해 특별히 설계된 알고리즘으로, 데이터를 임의로 분할하고 분할 횟수를 기반으로 이상치를 식별합니다.
   - **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**: 밀도 기반 클러스터링 알고리즘으로, 밀도가 낮은 지역의 데이터 포인트를 이상치로 간주합니다.



문제를 이해하는 과정

### 솔루션 워크플로

1. 문제이해
2. EDA 탐색적 데이터 분석
3. Local Validation
4. 지속적인 개선을 포함하는 모델링



### 문제이해

데이터 타입을 파악

Data Type: tabular data, time series, images, text, etc...



### 문제 유형

problem type: classification, regression, ranking, etc



### 평가 지표

ROC AUC, F1 Score, mse

대부분 sklearn에서 구현되지만 그렇지 않는 경우 수동으로 구현. ex) RMSLE

```python
def rmsle(y_true, y_pred):
    diffs = np.log(y_true + 1) - np.log(y_pred + 1)
    squares = np.power(diffs, 2)
    err = np.sqrt(np.mean(squares))
    return err
```





Categorical 데이터

범주형의 데이터 인코딩방법은 정말 다양하다.

Label encoding하게되면 생기는 문제점이 있다,

라벨 인코딩은 범주형 값을 숫자로 변환한다. 예를 들어, 'Red', 'Blue', 'Green'을 각각 0, 1, 2로 변환할 수 있다.  'Green' (2)이 'Red' (0)보다 더 중요하거나 크다는 의미가 부여될 수 있는데 이 과정에서 데이터에 원래 없던 순서나 중요도가 부여된다.

많은 머신 러닝 알고리즘은 숫자 값 간의 관계를 중요하게 생각한다.  따라서 라벨 인코딩된 데이터는 모델이 해당 숫자의 크기나 순서를 중요한 특징으로 해석할 수 있다.

이러한 문제를 해결하기 위해 **원-핫 인코딩(One-Hot Encoding)**이나 **더미 변수(Dummy Variable) 인코딩** 등의 대안적인 방법이 사용된다. 이러한 방법들은 범주 간의 순서를 고려하지 않으므로, 라벨 인코딩에서 발생할 수 있는 순서 정보의 잘못된 부여 문제를 해결할 수 있다. 하지만 이들 방법 역시 고차원성(High Dimensionality)과 같은 자체적인 문제점을 가지고 있다.

라벨 인코딩이 적합한 모델은 **트리 기반 모델**이다. 트리기반 모델들은 데이터의 순서 정보를 분할 기준으로 사용할 수 있으며, 범주 간의 상대적인 순서를 의미 있는 방식으로 해석할 수 있다.



Kaggle에서 가장 많이 사용하는 방식은 Target encoding이다.

서로 다른 범주의 수가 많을 때를 생각해보자. (High cardinality). 라벨 인코딩은 높은 값을 부여할 것이고, 원핫인코딩은 많은 피쳐를 만들어서 문제를 야기한다.



범주와 대상 변수간의 상관관계를 소개한다.

Kaggle에서 가장 자주 사용되는 mean target encoding을 고려한다.

1. 훈련데이터에 대해 카테고리별 평균값을 계산한다. 그런 다음 이 통계를 테스트 데이터의 해당 범주에 적용한다.
2. 훈련데이터를 K fold한다. 각 fold에 대해 평균을 계산하고 테스트 데이터의 K번째 fold에 적용한다.
3. **Mean target encoded feature**를 생성한다.



## Sklean - Impute

Scikit-Learn에서 누락된 데이터를 처리하기 위한 여러가지 **impute** 방법을 제공한다.

* **[SimpleImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer)**
  * strategy 파라미터를 사용하여 누락된 값을 평균(mean), 중앙값(median), 최빈값(mode), 또는 상수(constant)로 대체 한다.
* **[IterativeImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html#sklearn.impute.IterativeImputer)**
  * 각 피쳐의 누락된 값을 **다른 피쳐들을 이용해** 예측하여 채운다.
* **[KNNImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html#sklearn.impute.KNNImputer)**
  * KNN알고리즘을 사용하여 누락된 값을 대체한다.
* **[MissingIndicator](https://scikit-learn.org/stable/modules/generated/sklearn.impute.MissingIndicator.html)**
  * 누락된 값을 대체하는것이 아닌 누락된 값을 True로, 값이 있으면 False로 구성하는 새로운 이진피쳐를 생성한다.





