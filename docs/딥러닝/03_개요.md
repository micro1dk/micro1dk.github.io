---
title: Framework Overview
layout: default
parent: 신경망 구현
nav_order: 3
---

# Framework

신경망 모델이 수학적으로 하려고 하는일이 무엇인지 생각해보자. 신경망 모델이 수학적으로 하는 일은 결과값의 최솟값을 찾는 것이다. 신경망 모델의 성공확률을 높이는 연구된 기법이 몇 가지 있다. 그 기법의 이론을 공부하고 이해해야만 성공률이 높은 모델을 만들 수 있을것이다.

여러가지 활성화함수를 사용하여 학습속도를 개선해보고, 모멘텀을 사용해보고, 학습률 감쇠, 가중치 초기화, 드롭아웃을 사용해서 모델의 정확도를 높여보자.

프레임워크는 일관성과 유지보수성을 생각하여 만들어야한다. 딥러닝 프레임워크를 만들 때 고려해야할 핵심 클래스들은 다음과 같다.

1. **Matrix**
2. **Operation**
3. **Layer**
4. **Loss**
5. **Optimizer**
6. **Model**
7. **Trainer**



### Matrix



### Layer

신경망의 각 층을 나타낸다. 각 층은 행렬을 입력으로 받아 행렬을 출력하는 Forward, Backward의 메서드를 가진다.

**Linear, Sigmoid, ReLU, Tanh, Dropout, Convolution, GRU, LSTM** 등



### Operation

층의 연산으로 구성된다. 다음과 같은 메서드를 포함해야한다.

* forward(input):  연산의 순방향을 계산한다. 예를 들어, 덧셈 연산인 경우 입력을 받아서 더한 후 출력한다.
* backward(output_grad): 체인룰에 따라 기울기를 계산한다.



### Loss

모델의 출력과 실제 값 사이의 차이를 계산하는 손실함수를 정의한다. **Mean Squared Error, Binary Cross Entropy, Categorical CrossEntropy** 등



### Optimizer

모델의 가중치들을 업데이트하는 최적화 알고리즘을 정의한다. **SGD, SGD Momentum, AdaGrad, RMSProp, Adam** 등 



### Model

여러 Layer들을 연결하여 신경망 모델을 구성한다. 순방향 계산과 역방향 계산을 수행하는 메서드를 포함한다.



### Trainer

전체 학습 프로세스를 조정한다. 각 에폭에서 Batch데이터를 가져와 모델에 공급하고, 손실을 계산하고 Optimizer를 사용하여 가중치를 업데이트 시킨다.


